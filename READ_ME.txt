This web crawler crawls to websites using multi.threading with the class spider.
Each class has shared variables mainly queue and crawled files(so to avoid any same links crawling)(sets are used in addition to avoid redundancy)
EACH WEB CRAWALING PROJECT creates a seperate file, with each file having it's own crawl and queue files.
A limit is set ot crawling otherwise it ends in a long loop as there are many webpages to crawl(not infinite as it's hardcoded to stay in the domain.)

Project Done By Group 2:-
Abhinav 202101002
Kshitij 202101017
Aastha Gupta 202101049
Eeshita Sood 202101012
Shivani singla 202101025
Vaishali Rana 202101036

